{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robot Learning assignmnet 04\n",
    "# Team members: Roberto Cai / Ramesh Kumar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GridWorld(object):\n",
    "    def __init__(self, episodes):\n",
    "        self.grid_world = np.array([[1,0,0,0,0,0,0],\n",
    "                                    [0,0,0,1,1,1,0],\n",
    "                                    [2,1,1,0,1,0,0],\n",
    "                                    [0,0,1,0,1,0,3],\n",
    "                                    [1,1,0,1,0,1,0]])# 0: empty, 1: W, 2: G, 3: S\n",
    "        # contains all possible rewards\n",
    "        self.rewards = {0:-1, 1:-20, 2:100, 3:-1}\n",
    "        \n",
    "        # Col 0 contains actions\n",
    "        # col 1 contains probabilities\n",
    "        # col 2 and 3 are used for obtaining next state\n",
    "        # col 4 unicode values for arrows\n",
    "        self.actions = np.array([[0,0, -1, 0, 8593],      # up\n",
    "                                 [1,0, -1, 1, 8599],      # upper right\n",
    "                                 [2,0, 0, 1, 8594],       # right\n",
    "                                 [3,0, 1, 1, 8600],       # lower right\n",
    "                                 [4,0, 1, 0, 8595],       # down\n",
    "                                 [5,0.25, 1, -1, 8601],   # lower left\n",
    "                                 [6,0.5, 0, -1, 8592],    # left\n",
    "                                 [7,0.25, -1, -1, 8598]]) # upper left\n",
    "        self.n_actions = 8\n",
    "        self.transition_probability = np.array([0.15,0.7,0.15]) # left diagonal, desired direction, right diagonal\n",
    "        self.episodes = episodes\n",
    "        self.rows = 5\n",
    "        self.cols = 7\n",
    "        self.gamma = 1\n",
    "        self.epsilon = 0.1\n",
    "        self.alpha = 1\n",
    "        self.states = self.rows*self.cols\n",
    "    \n",
    "    # get the expected value of a state\n",
    "    def get_value(self,row,col):\n",
    "        index = row*self.rows + col\n",
    "        return self.V[index]\n",
    "    \n",
    "    # get the wind direction for non deterministic action\n",
    "    # 0: deviation to right, 1: desired action, 2: deviation to left\n",
    "    def stochastic_action(self):\n",
    "        rand = np.random.random()\n",
    "        for i in range(3):\n",
    "            totalsum = np.sum(self.transition_probability[:i+1])\n",
    "            if rand < totalsum:\n",
    "                direction = i\n",
    "                break\n",
    "        return direction\n",
    "    \n",
    "    # select an action acording to probabilities\n",
    "    def get_action(self):\n",
    "        rand = np.random.random()\n",
    "        for i in range(self.n_actions):\n",
    "            totalsum = np.sum(self.actions[:i+1,1])\n",
    "            if rand < totalsum:\n",
    "                action = i\n",
    "                break\n",
    "        direction = self.stochastic_action()\n",
    "        if direction == 0: # deviation to the right\n",
    "            if action < 7:\n",
    "                action += 1\n",
    "            else:\n",
    "                action = 0\n",
    "        if direction == 2: # deviation to the left\n",
    "            if action > 0:\n",
    "                action += -1\n",
    "            else:\n",
    "                action = 7\n",
    "        return action\n",
    "    \n",
    "    # choose action with max action value\n",
    "    def get_greedy_action(self, row, col):\n",
    "        index = row*7 + col\n",
    "        a_index = np.argmax(self.Q[index,:])\n",
    "        return a_index\n",
    "    \n",
    "    # obtain next state according to current state and selected action\n",
    "    def get_next_state(self, row, col, action):\n",
    "        if action == 0: # up\n",
    "            if row == 0:\n",
    "                r = row\n",
    "                c = col \n",
    "            else:\n",
    "                r = row + self.actions[action,2]\n",
    "                c = col + self.actions[action,3]\n",
    "        elif action == 1: # upper right\n",
    "            if row == 0 and col != 6:\n",
    "                r = row\n",
    "                c = col + self.actions[action,3]\n",
    "            elif row == 0 and col == 6:\n",
    "                r = row\n",
    "                c = col\n",
    "            elif row != 0 and col == 6:\n",
    "                r = row + self.actions[action,2]\n",
    "                c = col\n",
    "            else:\n",
    "                r = row + self.actions[action,2]\n",
    "                c = col + self.actions[action,3]\n",
    "        elif action == 2: # left\n",
    "            if col == 6:\n",
    "                r = row\n",
    "                c = col \n",
    "            else:\n",
    "                r = row + self.actions[action,2]\n",
    "                c = col + self.actions[action,3]\n",
    "        elif action == 3: # lower right\n",
    "            if row == 4 and col != 6:\n",
    "                r = row\n",
    "                c = col + self.actions[action,3]\n",
    "            elif row == 4 and col == 6:\n",
    "                r = row\n",
    "                c = col\n",
    "            elif row != 4 and col == 6:\n",
    "                r = row + self.actions[action,2]\n",
    "                c = col\n",
    "            else:\n",
    "                r = row + self.actions[action,2]\n",
    "                c = col + self.actions[action,3]\n",
    "        elif action == 4: # down\n",
    "            if row == 4:\n",
    "                r = row\n",
    "                c = col \n",
    "            else:\n",
    "                r = row + self.actions[action,2]\n",
    "                c = col + self.actions[action,3]\n",
    "        elif action == 5: # lower left\n",
    "            if row == 4 and col != 0:\n",
    "                r = row\n",
    "                c = col + self.actions[action,3]\n",
    "            elif row == 4 and col == 0:\n",
    "                r = row\n",
    "                c = col\n",
    "            elif row != 4 and col == 0:\n",
    "                r = row + self.actions[action,2]\n",
    "                c = col\n",
    "            else:\n",
    "                r = row + self.actions[action,2]\n",
    "                c = col + self.actions[action,3]\n",
    "        elif action == 6: # left\n",
    "            if col == 0:\n",
    "                r = row\n",
    "                c = col \n",
    "            else:\n",
    "                r = row + self.actions[action,2]\n",
    "                c = col + self.actions[action,3]\n",
    "        elif action == 7: # upper left\n",
    "            if row == 0 and col != 0:\n",
    "                r = row\n",
    "                c = col + self.actions[action,3]\n",
    "            elif row == 0 and col == 0:\n",
    "                r = row\n",
    "                c = col\n",
    "            elif row != 0 and col == 0:\n",
    "                r = row + self.actions[action,2]\n",
    "                c = col\n",
    "            else:\n",
    "                r = row + self.actions[action,2]\n",
    "                c = col + self.actions[action,3]\n",
    "        return int(r), int(c)\n",
    "    \n",
    "    # obtain reward of next state\n",
    "    def get_reward(self,row, col):\n",
    "        return self.rewards[self.grid_world[row,col]]\n",
    "    \n",
    "    \n",
    "    def td0_policy_evaluation(self):\n",
    "        # initialize V values\n",
    "        self.V = np.zeros(self.states)\n",
    "        for i in range(self.episodes):\n",
    "            # initial state\n",
    "            row = 3\n",
    "            col = 6\n",
    "            \n",
    "            is_terminal = True\n",
    "            # loop until a terminal state is found\n",
    "            while is_terminal:\n",
    "                \n",
    "                a = self.get_action()\n",
    "                \n",
    "                nrow, ncol = self.get_next_state(row, col, a)\n",
    "\n",
    "                reward = self.get_reward(nrow, ncol)\n",
    "                \n",
    "                # calculate index of current state\n",
    "                oind = (row)*7 + col\n",
    "                # calculate index of new state\n",
    "                nind = (nrow)*7 + ncol\n",
    "                \n",
    "                # update V \n",
    "                self.V[oind] = self.V[oind] + self.alpha*(reward + self.gamma*self.V[nind] - self.V[oind])\n",
    "                \n",
    "                row = nrow\n",
    "                col = ncol\n",
    "                \n",
    "                # End if next state is W or G\n",
    "                if self.grid_world[row,col] in (1,2):\n",
    "                    is_terminal = False\n",
    "        return self.V\n",
    "        \n",
    "    def q_learning(self):\n",
    "        # initialize V, Q and policy values\n",
    "        self.V = np.zeros(self.states)\n",
    "        self.Q = np.zeros((self.states,self.n_actions))\n",
    "        self.policy = []\n",
    "        for i in range(self.episodes):\n",
    "            # initial state\n",
    "            row = 3\n",
    "            col = 6\n",
    "            \n",
    "            is_terminal = True\n",
    "            # loop until a terminal state is found\n",
    "            while is_terminal:\n",
    "                rand_a = np.random.random()\n",
    "                # select e-greedy action \n",
    "                if rand_a < self.epsilon:\n",
    "                    a = self.get_greedy_action(row,col)\n",
    "                # select action acording to policy\n",
    "                else:\n",
    "                    a = self.get_action()\n",
    "                \n",
    "                nrow, ncol = self.get_next_state(row, col, a)\n",
    "                \n",
    "                reward = self.get_reward(nrow, ncol)\n",
    "                \n",
    "                # calculate index of current state\n",
    "                oind = (row)*7 + col\n",
    "                # calculate index of new state\n",
    "                nind = (nrow)*7 + ncol\n",
    "                \n",
    "                # get the action with max action value\n",
    "                q_ind = np.argmax(self.Q[nind,:])\n",
    "                \n",
    "                # update Q\n",
    "                self.Q[oind,a] = self.Q[oind,a] + self.alpha*(reward + self.gamma*self.Q[nind,q_ind] - self.Q[oind,a])\n",
    "                \n",
    "                row = nrow\n",
    "                col = ncol\n",
    "                \n",
    "                # End if next state is W or G\n",
    "                if self.grid_world[row,col] in (1,2):\n",
    "                    is_terminal = False\n",
    "        # compute resulting V and policy\n",
    "        for i in range(self.states):\n",
    "            row = int(i / 7)\n",
    "            col = i % 7\n",
    "            q_ind = np.argmax(self.Q[i,:])\n",
    "            if self.grid_world[row,col] in (1,2):\n",
    "                self.policy.append('-1')\n",
    "            else:\n",
    "#                 print(int(self.actions[q_ind,4]))\n",
    "                self.policy.append(chr(int(self.actions[q_ind,4])))\n",
    "            self.V[i] = self.Q[i,q_ind]\n",
    "            \n",
    "        return self.Q, self.V, self.policy\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>-21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>-21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1     2     3     4     5     6\n",
       "0  0.0  0.0   0.0   0.0   0.0   0.0   0.0\n",
       "1  0.0  0.0   0.0   0.0   0.0   0.0   0.0\n",
       "2  0.0  0.0   0.0   0.0   0.0 -20.0 -21.0\n",
       "3  0.0  0.0   0.0 -20.0   0.0 -20.0 -21.0\n",
       "4  0.0  0.0 -20.0   0.0 -20.0   0.0 -20.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridWorld(500)\n",
    "v = grid.td0_policy_evaluation()\n",
    "v.shape = (5,7)\n",
    "\n",
    "pd.DataFrame(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1     2     3     4     5     6\n",
       "0    0.0   99.0  99.0  98.0  97.0  96.0   0.0\n",
       "1  100.0  100.0  99.0   0.0   0.0   0.0  95.0\n",
       "2    0.0    0.0   0.0  98.0   0.0  95.0  95.0\n",
       "3  100.0  100.0   0.0  98.0   0.0  96.0  95.0\n",
       "4    0.0    0.0  99.0   0.0  97.0   0.0  95.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridWorld(5000)\n",
    "q, v, policy = grid.q_learning()\n",
    "v.shape = (5,7)\n",
    "pd.DataFrame(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>↙</td>\n",
       "      <td>↙</td>\n",
       "      <td>↙</td>\n",
       "      <td>←</td>\n",
       "      <td>←</td>\n",
       "      <td>→</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>↙</td>\n",
       "      <td>↙</td>\n",
       "      <td>←</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>↖</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>↖</td>\n",
       "      <td>-1</td>\n",
       "      <td>↓</td>\n",
       "      <td>↙</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>↑</td>\n",
       "      <td>↖</td>\n",
       "      <td>-1</td>\n",
       "      <td>↙</td>\n",
       "      <td>-1</td>\n",
       "      <td>↙</td>\n",
       "      <td>←</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>↖</td>\n",
       "      <td>-1</td>\n",
       "      <td>↖</td>\n",
       "      <td>-1</td>\n",
       "      <td>↖</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1   2   3   4   5  6\n",
       "0  -1   ↙   ↙   ↙   ←   ←  →\n",
       "1   ↙   ↙   ←  -1  -1  -1  ↖\n",
       "2  -1  -1  -1   ↖  -1   ↓  ↙\n",
       "3   ↑   ↖  -1   ↙  -1   ↙  ←\n",
       "4  -1  -1   ↖  -1   ↖  -1  ↖"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = np.asarray(policy)\n",
    "policy.shape = (5,7)\n",
    "pd.DataFrame(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
