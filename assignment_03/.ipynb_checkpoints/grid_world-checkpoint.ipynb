{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team members"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roberto Cai Wu / Ramesh Kumar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GridWorld(object):\n",
    "    def __init__(self):\n",
    "        # create an array for grid \n",
    "        # 0 represents empty cell, 1 represents *, and 2 represents x\n",
    "        self.grid = np.array([[0,0,0,0,0,0,0,0,0],\n",
    "                              [0,1,1,1,1,2,0,0,0],\n",
    "                              [0,2,2,2,0,2,2,0,0],\n",
    "                              [0,0,0,0,0,0,0,2,0],\n",
    "                              [0,0,2,2,2,2,0,2,0],\n",
    "                              [0,0,0,0,0,0,0,2,0],\n",
    "                              [0,2,2,2,0,2,2,0,0],\n",
    "                              [0,0,0,0,0,0,0,0,3],\n",
    "                              [0,1,1,1,2,1,1,0,2]]) \n",
    "        self.rewards = {0:-1, 1:5, 2:-20, 3:100} # rewards \n",
    "        self.actions = np.array([[1, 0.125],[2, 0.125], [3, 0.625],[4, 0.125]]) #up,right,down,left with probabilities\n",
    "        self.transition_probability = np.array([0.2,0.6,0.2]) # left diagonal, desired direction, right diagonal\n",
    "        self.gama = 0.9  # discount factor\n",
    "        self.threshold = 0.0001  # theta\n",
    "        self.n=9  # number of rows \n",
    "        self.a=4  # number of actions\n",
    "        self.states = self.n*self.n\n",
    "\n",
    "    def get_next_state(self,row,col,a):\n",
    "        # going up\n",
    "        if a == 1:\n",
    "            # if state is in row 0 it stays in same row\n",
    "            if row == 0:\n",
    "                r = row\n",
    "                c = col\n",
    "                reward = -10\n",
    "            else:\n",
    "                # if next state is not reachable\n",
    "                reward = self.rewards[self.grid[row-1,col]]\n",
    "                if self.grid[row-1,col] == 2:\n",
    "                    r = row\n",
    "                    c = col\n",
    "                # if next state is reachable and no obstacle\n",
    "                else:\n",
    "                    r = row-1\n",
    "                    c = col\n",
    "        # go right\n",
    "        elif a == 2:\n",
    "            # if state is in last column it stays in same column\n",
    "            if col == 8:\n",
    "                r = row\n",
    "                c = col\n",
    "                reward = -10\n",
    "            else:\n",
    "                # if next state is not reachable\n",
    "                reward = self.rewards[self.grid[row,col+1]]\n",
    "                if self.grid[row,col+1] == 2:\n",
    "                    r = row\n",
    "                    c = col\n",
    "                # if next state is reachable and no obstacle\n",
    "                else:\n",
    "                    r = row\n",
    "                    c = col+1\n",
    "        # go down\n",
    "        elif a == 3:\n",
    "            # if state is in row 8 it stays in same row\n",
    "            if row == 8:\n",
    "                r = row\n",
    "                c = col\n",
    "                reward = -10\n",
    "            else:\n",
    "                # if next state is not reachable\n",
    "                reward = self.rewards[self.grid[row+1,col]]\n",
    "                if self.grid[row+1,col] == 2:\n",
    "                    r = row\n",
    "                    c = col\n",
    "                # if next state is reachable and no obstacle\n",
    "                else:\n",
    "                    r = row+1\n",
    "                    c = col\n",
    "        # go left\n",
    "        elif a == 4:\n",
    "            # if state is in first column it stays in same column\n",
    "            if col == 0:\n",
    "                r = row\n",
    "                c = col\n",
    "                reward = -10\n",
    "            else:\n",
    "                # if next state is not reachable\n",
    "                reward = self.rewards[self.grid[row,col-1]]\n",
    "                if self.grid[row,col-1] == 2:\n",
    "                    r = row\n",
    "                    c = col\n",
    "                # if next state is reachable and no obstacle\n",
    "                else:\n",
    "                    r = row\n",
    "                    c = col-1\n",
    "        return r,c,reward\n",
    "    \n",
    "    # states with undeterministic action\n",
    "    # 0.6 probability to move in desired direction, 0.2 to move left diagonal, 0.2 for right diagonal\n",
    "    def get_next_non_determinstic_state(self,row,col,a):\n",
    "        self.possible_states = np.zeros((3,4))\n",
    "        # going up\n",
    "        if a == 1:\n",
    "            for i in range(3):\n",
    "                # going up,Diagonaly left\n",
    "                if i == 0:\n",
    "                    if row == 0:\n",
    "                        r = row\n",
    "                        c = col\n",
    "                        reward = -10\n",
    "                    else:\n",
    "                        if col == 0:\n",
    "                            r = row\n",
    "                            c = col\n",
    "                            reward = -10\n",
    "                        else:\n",
    "                            reward = self.rewards[self.grid[row-1,col-1]]\n",
    "                            if self.grid[row-1,col] == 2:\n",
    "                                r = row\n",
    "                                c = col\n",
    "                            # if next state is reachable and no obstacle\n",
    "                            else:\n",
    "                                r = row-1\n",
    "                                c = col-1\n",
    "                    prob = self.transition_probability[i]\n",
    "                #going up, Desired direction\n",
    "                if i == 1:\n",
    "                    if row == 0:\n",
    "                        r = row\n",
    "                        c = col\n",
    "                        reward = -10\n",
    "                    else:\n",
    "                        reward = self.rewards[self.grid[row-1,col]]\n",
    "                        if self.grid[row-1,col] == 2:\n",
    "                            r = row\n",
    "                            c = col\n",
    "                        # if next state is reachable and no obstacle\n",
    "                        else:\n",
    "                            r = row-1\n",
    "                            c = col\n",
    "                    prob = self.transition_probability[i]\n",
    "                # going up,Diagonally right\n",
    "                if i == 2:\n",
    "                    if row == 0:\n",
    "                        r = row\n",
    "                        c = col\n",
    "                        reward = -10\n",
    "                    else:\n",
    "                        if col == 8:\n",
    "                            r = row\n",
    "                            c = col\n",
    "                            reward = -10\n",
    "                        else:\n",
    "                            reward = self.rewards[self.grid[row-1,col+1]]\n",
    "                            if self.grid[row-1,col+1] == 2:\n",
    "                                r = row\n",
    "                                c = col\n",
    "                            # if next state is reachable and no obstacle\n",
    "                            else:\n",
    "                                r = row-1\n",
    "                                c = col+1\n",
    "                    prob = self.transition_probability[i]\n",
    "                self.possible_states[i,:] = np.array([r,c,reward,prob])\n",
    "        # going right \n",
    "        if a == 2:\n",
    "            for i in range(3):\n",
    "                # going right, Diagonaly left\n",
    "                if i == 0:\n",
    "                    if col == 8:\n",
    "                        r = row\n",
    "                        c = col\n",
    "                        reward = -10\n",
    "                    else:\n",
    "                        if row == 0:\n",
    "                            r = row\n",
    "                            c = col\n",
    "                            reward = -10\n",
    "                        else:\n",
    "                            reward = self.rewards[self.grid[row-1,col+1]]\n",
    "                            if self.grid[row-1,col+1] == 2:\n",
    "                                r = row\n",
    "                                c = col\n",
    "                            # if next state is reachable and no obstacle\n",
    "                            else:\n",
    "                                r = row-1\n",
    "                                c = col+1\n",
    "                    prob = self.transition_probability[i]\n",
    "                # going right,Desired direction\n",
    "                if i == 1:\n",
    "                    if col == 8:\n",
    "                        r = row\n",
    "                        c = col\n",
    "                        reward = -10\n",
    "                    else:\n",
    "                        reward = self.rewards[self.grid[row,col+1]]\n",
    "                        if self.grid[row,col+1] == 2:\n",
    "                            r = row\n",
    "                            c = col\n",
    "                        # if next state is reachable and no obstacle\n",
    "                        else:\n",
    "                            r = row\n",
    "                            c = col+1\n",
    "                    prob = self.transition_probability[i]\n",
    "                # going right,Diagonally right\n",
    "                if i == 2:\n",
    "                    if col == 8:\n",
    "                        r = row\n",
    "                        c = col\n",
    "                        reward = -10\n",
    "                    else:\n",
    "                        if row == 8:\n",
    "                            r = row\n",
    "                            c = col\n",
    "                            reward = -10\n",
    "                        else:\n",
    "                            reward = self.rewards[self.grid[row+1,col+1]]\n",
    "                            if self.grid[row+1,col+1] == 2:\n",
    "                                r = row\n",
    "                                c = col\n",
    "                            # if next state is reachable and no obstacle\n",
    "                            else:\n",
    "                                r = row+1\n",
    "                                c = col+1\n",
    "                    prob = self.transition_probability[i]\n",
    "                self.possible_states[i,:] = np.array([r,c,reward,prob])\n",
    "        # going down\n",
    "        if a == 3:\n",
    "            for i in range(3):\n",
    "                # going down,  Diagonaly left\n",
    "                if i == 0:\n",
    "                    if row == 8:\n",
    "                        r = row\n",
    "                        c = col\n",
    "                        reward = -10\n",
    "                    else:\n",
    "                        if col == 8:\n",
    "                            r = row\n",
    "                            c = col\n",
    "                            reward = -10\n",
    "                        else:\n",
    "                            reward = self.rewards[self.grid[row+1,col+1]]\n",
    "                            if self.grid[row+1,col+1] == 2:\n",
    "                                r = row\n",
    "                                c = col\n",
    "                            # if next state is reachable and no obstacle\n",
    "                            else:\n",
    "                                r = row+1\n",
    "                                c = col+1\n",
    "                    prob = self.transition_probability[i]\n",
    "                # going down, Desired direction\n",
    "                if i == 1:\n",
    "                    if row == 8:\n",
    "                        r = row\n",
    "                        c = col\n",
    "                        reward = -10\n",
    "                    else:\n",
    "                        reward = self.rewards[self.grid[row+1,col]]\n",
    "                        if self.grid[row+1,col] == 2:\n",
    "                            r = row\n",
    "                            c = col\n",
    "                        # if next state is reachable and no obstacle\n",
    "                        else:\n",
    "                            r = row+1\n",
    "                            c = col\n",
    "                    prob = self.transition_probability[i]\n",
    "                # going down, Diagonally right\n",
    "                if i == 2:\n",
    "                    if row == 8:\n",
    "                        r = row\n",
    "                        c = col\n",
    "                        reward = -10\n",
    "                    else:\n",
    "                        if col == 0:\n",
    "                            r = row\n",
    "                            c = col\n",
    "                            reward = -10\n",
    "                        else:\n",
    "                            reward = self.rewards[self.grid[row+1,col-1]]\n",
    "                            if self.grid[row+1,col-1] == 2:\n",
    "                                r = row\n",
    "                                c = col\n",
    "                            # if next state is reachable and no obstacle\n",
    "                            else:\n",
    "                                r = row+1\n",
    "                                c = col-1\n",
    "                    prob = self.transition_probability[i]\n",
    "                self.possible_states[i,:] = np.array([r,c,reward,prob])\n",
    "        # going left \n",
    "        if a == 4:\n",
    "            for i in range(3):\n",
    "                # going left,  Diagonaly left\n",
    "                if i == 0:\n",
    "                    if col == 0:\n",
    "                        r = row\n",
    "                        c = col\n",
    "                        reward = -10\n",
    "                    else:\n",
    "                        if row == 8:\n",
    "                            r = row\n",
    "                            c = col\n",
    "                            reward = -10\n",
    "                        else:\n",
    "                            reward = self.rewards[self.grid[row+1,col-1]]\n",
    "                            if self.grid[row+1,col-1] == 2:\n",
    "                                r = row\n",
    "                                c = col\n",
    "                            # if next state is reachable and no obstacle\n",
    "                            else:\n",
    "                                r = row+1\n",
    "                                c = col-1\n",
    "                    prob = self.transition_probability[i]\n",
    "                # going left, Desired direction\n",
    "                if i == 1:\n",
    "                    if col == 0:\n",
    "                        r = row\n",
    "                        c = col\n",
    "                        reward = -10\n",
    "                    else:\n",
    "                        reward = self.rewards[self.grid[row,col-1]]\n",
    "                        if self.grid[row,col-1] == 2:\n",
    "                            r = row\n",
    "                            c = col\n",
    "                        # if next state is reachable and no obstacle\n",
    "                        else:\n",
    "                            r = row\n",
    "                            c = col-1\n",
    "                    prob = self.transition_probability[i]\n",
    "                # going left, Diagonally right\n",
    "                if i == 2:\n",
    "                    if col == 0:\n",
    "                        r = row\n",
    "                        c = col\n",
    "                        reward = -10\n",
    "                    else:\n",
    "                        if row == 0:\n",
    "                            r = row\n",
    "                            c = col\n",
    "                            reward = -10\n",
    "                        else:\n",
    "                            reward = self.rewards[self.grid[row-1,col-1]]\n",
    "                            if self.grid[row-1,col-1] == 2:\n",
    "                                r = row\n",
    "                                c = col\n",
    "                            # if next state is reachable and no obstacle\n",
    "                            else:\n",
    "                                r = row-1\n",
    "                                c = col-1\n",
    "                    prob = self.transition_probability[i]\n",
    "                self.possible_states[i,:] = np.array([r,c,reward,prob])\n",
    "        return self.possible_states\n",
    "        \n",
    "    # get the expected reward of state\n",
    "    def get_value(self,row,col):\n",
    "        index = row*9 + col\n",
    "        return self.V[index]\n",
    "    \n",
    "    # get the values of next state\n",
    "    def get_next_state_value(self, row, col):\n",
    "        A_v = np.zeros(self.a)\n",
    "        for j in range(1,5): # for each action\n",
    "            r,c,reward = self.get_next_state(row,col,j) # get next state and reward\n",
    "            next_s = r*9 + c\n",
    "            next_v = self.get_value(r,c) # get value from next state\n",
    "            prob = self.actions[j-1,1] # probability of action\n",
    "            A_v[j-1]  += prob*(reward + self.gama*next_v)\n",
    "        return A_v\n",
    "    \n",
    "    # get the value of non-deterministic states\n",
    "    def get_next_non_deterministic_state_value(self, row, col):\n",
    "        A_v = np.zeros(self.a)\n",
    "        for j in range(1,5): # for each action\n",
    "            possible_states = self.get_next_non_determinstic_state(row,col,j) # get next state and reward\n",
    "            for s in range(3):\n",
    "                next_s = possible_states[s,0]*9 + possible_states[s,1]\n",
    "                next_v = self.get_value(possible_states[s,0],possible_states[s,1]) # get value from nest state\n",
    "                prob = self.actions[j-1,1] # probability of action\n",
    "                A_v[j-1]  +=  possible_states[s,3]*prob*(possible_states[s,2] + self.gama*next_v)\n",
    "        return A_v\n",
    "    \n",
    "    # evaluate the policy\n",
    "    def policy_evaluation(self):        \n",
    "        self.V = np.zeros(self.states)\n",
    "        count = 0\n",
    "        iterate = True\n",
    "        while iterate:\n",
    "        \n",
    "            delta = 0\n",
    "            for i in range(self.states):\n",
    "                row = int(i / self.n)\n",
    "                col = i % self.n\n",
    "                s = self.grid[row,col]\n",
    "                v = 0\n",
    "                if s != 2 and s != 3:\n",
    "                    for j in range(1,5): # for each action\n",
    "                        r,c,reward = self.get_next_state(row,col,j) # get next state and reward\n",
    "                        next_s = r*9 + c\n",
    "                        next_v = self.get_value(r,c) # get value from nest state\n",
    "                        prob = self.actions[j-1,1] # probability of action\n",
    "                        v  += prob*(reward + self.gama*next_v)\n",
    "        \n",
    "                    delta = max(delta, np.abs(v - self.V[i]))\n",
    "                self.V[i] = v\n",
    "            count += 1\n",
    "            # if delta is smaller than certain threshold, it stops.\n",
    "            if delta < self.threshold:\n",
    "                break\n",
    "        return self.V, delta, count\n",
    "\n",
    "    # value iteration\n",
    "    def value_iteration(self):        \n",
    "        self.V = np.zeros(self.states)\n",
    "        self.policy = np.zeros((self.states,self.a))\n",
    "        count = 0\n",
    "        iterate = True\n",
    "        while iterate:\n",
    "        #     print(count)\n",
    "            delta = 0\n",
    "            for i in range(self.states):\n",
    "                row = int(i / self.n)\n",
    "                col = i % self.n\n",
    "                s = self.grid[row,col]\n",
    "                best_v = 0\n",
    "                # if state is either * or x, then values of those state remain same\n",
    "                if s != 2 and s != 3:\n",
    "                    values = self.get_next_state_value(row,col)\n",
    "                    best_v = max(values)\n",
    "                    delta = max(delta, np.abs(best_v- self.V[i]))\n",
    "                self.V[i] = best_v\n",
    "            count += 1\n",
    "            if delta < self.threshold:\n",
    "                break\n",
    "        \n",
    "        for i in range(self.states):\n",
    "            row = int(i / self.n)\n",
    "            col = i % self.n\n",
    "            values = self.get_next_state_value(row,col)\n",
    "            # take action with maximum value\n",
    "            best_v = np.argmax(values)\n",
    "            self.policy[i,best_v] = 1\n",
    "        # Deterministic policy     \n",
    "        return self.V, delta, count, self.policy\n",
    "\n",
    "    # non-deterministic actions\n",
    "    def non_deterministic_value_iteration(self):        \n",
    "        self.V = np.zeros(self.states)\n",
    "        self.policy = np.zeros((self.states,self.a))\n",
    "        count = 0\n",
    "        iterate = True\n",
    "        while iterate:\n",
    "        \n",
    "            delta = 0\n",
    "            for i in range(self.states):\n",
    "                row = int(i / self.n)\n",
    "                col = i % self.n\n",
    "                s = self.grid[row,col]\n",
    "                best_v = 0\n",
    "                if s != 2 and s != 3:\n",
    "                    values = self.get_next_non_deterministic_state_value(row,col)\n",
    "                    best_v = max(values)\n",
    "                    delta = max(delta, np.abs(best_v- self.V[i]))\n",
    "                self.V[i] = best_v\n",
    "            count += 1\n",
    "            if delta < self.threshold:\n",
    "                break\n",
    "        # Deterministic policy\n",
    "        for i in range(self.states):\n",
    "            row = int(i / self.n)\n",
    "            col = i % self.n\n",
    "            values = self.get_next_state_value(row,col)\n",
    "            best_v = np.argmax(values)\n",
    "            self.policy[i,best_v] = 1\n",
    "             \n",
    "        return self.V, delta, count, self.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_world = GridWorld()\n",
    "np.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the expected value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta:  8.84684316986e-05\n",
      "number of iterations:  91\n",
      "V: [[ -50.1325  -64.5825  -72.6501  -76.663   -80.8102  -99.1518  -81.184\n",
      "   -50.6304  -20.1203]\n",
      " [ -50.3773  -80.2293  -89.2656  -93.1541  -95.2266    0.      -94.3562\n",
      "   -55.8449  -11.8174]\n",
      " [ -50.9674    0.        0.        0.     -110.7871    0.        0.\n",
      "   -66.1413    0.3255]\n",
      " [ -52.1465  -76.2994 -118.748  -131.1953 -124.7058 -128.5408 -111.0793\n",
      "     0.       19.8832]\n",
      " [ -53.0445  -80.2047    0.        0.        0.        0.     -117.1123\n",
      "     0.       35.3295]\n",
      " [ -53.4444  -94.6765 -120.0932 -116.7043  -81.4974 -119.7586 -128.9167\n",
      "     0.       52.6995]\n",
      " [ -51.0016    0.        0.        0.      -75.2922    0.        0.\n",
      "   -14.7547   73.5423]\n",
      " [ -51.58    -46.3409  -46.6047  -55.3156  -77.2143  -55.2259  -44.4511\n",
      "   -24.8149    0.    ]\n",
      " [ -58.1356  -54.1455  -53.8673  -63.1786    0.      -63.4678  -54.7925\n",
      "   -52.941     0.    ]]\n"
     ]
    }
   ],
   "source": [
    "V,delta, count = grid_world.policy_evaluation()\n",
    "V.shape = (9,9)\n",
    "print('delta: ',delta)\n",
    "print('number of iterations: ',count)\n",
    "print('V:', V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Value iteration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta: 1.6074364062e-12\n",
      "number of iterations: 9\n",
      "value: [[  2.7113e-01   3.5211e+00   3.5211e+00   3.5211e+00   3.5211e+00\n",
      "    2.7113e-01  -9.4498e-02  -5.7899e-02   5.9645e-01]\n",
      " [  7.0423e-01   7.0423e-01   7.0423e-01   7.0423e-01   7.0423e-01\n",
      "    0.0000e+00  -1.1158e-01   1.1929e-01   2.1715e+00]\n",
      " [ -4.5775e-02   0.0000e+00   0.0000e+00   0.0000e+00   7.0423e-01\n",
      "    0.0000e+00   0.0000e+00   4.3429e-01   4.9715e+00]\n",
      " [ -1.3015e-01  -1.3964e-01  -1.3964e-01  -1.3015e-01  -4.5775e-02\n",
      "   -1.3015e-01  -1.3964e-01   0.0000e+00   9.9493e+00]\n",
      " [ -1.3964e-01  -1.4071e-01   0.0000e+00   0.0000e+00   0.0000e+00\n",
      "    0.0000e+00  -1.4071e-01   0.0000e+00   1.8799e+01]\n",
      " [ -1.4071e-01  -1.4083e-01  -1.4084e-01  -1.4084e-01  -1.4084e-01\n",
      "   -1.4084e-01  -1.4083e-01   0.0000e+00   3.4531e+01]\n",
      " [ -1.4083e-01   0.0000e+00   0.0000e+00   0.0000e+00  -1.4085e-01\n",
      "    0.0000e+00   0.0000e+00   6.9062e+00   6.2500e+01]\n",
      " [  2.7113e-01   3.5211e+00   3.5211e+00   3.5211e+00   2.7113e-01\n",
      "    3.5211e+00   3.5211e+00   1.2500e+01   0.0000e+00]\n",
      " [  7.0423e-01   7.0423e-01   7.0423e-01   7.0423e-01   0.0000e+00\n",
      "    7.0423e-01   7.0423e-01   1.2812e+00   0.0000e+00]]\n",
      "\n",
      "0 = up, 1 = right, 2 = down, 3 = left \n",
      "\n",
      "[[1 2 2 2 2 3 3 1 2]\n",
      " [1 1 1 1 3 3 1 1 2]\n",
      " [0 0 0 0 0 3 1 1 2]\n",
      " [0 3 1 1 0 3 3 1 2]\n",
      " [0 0 0 0 0 0 0 1 2]\n",
      " [0 0 3 3 1 1 0 1 2]\n",
      " [0 2 2 2 0 2 2 1 2]\n",
      " [1 2 2 2 3 2 2 1 0]\n",
      " [1 1 1 3 1 1 3 0 0]]\n"
     ]
    }
   ],
   "source": [
    "V, delta, count, policy = grid_world.value_iteration()\n",
    "V.shape = (9,9)\n",
    "print('delta:', delta)\n",
    "print('number of iterations:', count)\n",
    "print('value:', V )\n",
    "print(\"\\n0 = up, 1 = right, 2 = down, 3 = left \\n\")\n",
    "print(np.reshape(np.argmax(policy,axis=1),(9,9)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Non-deterministic actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta: 2.41781135388e-05\n",
      "number of iterations: 12\n",
      "V:  [[ -3.4424e-02   2.4274e+00   3.2487e+00   3.2525e+00   2.7408e-02\n",
      "   -2.0397e-01  -3.8837e-01  -3.8826e-01  -3.8837e-01]\n",
      " [ -8.9903e-02   1.1117e-01   2.2208e-01   3.2202e-01  -5.4557e-02\n",
      "    0.0000e+00  -1.4719e-01  -1.5204e-01  -1.4719e-01]\n",
      " [ -2.0825e-01   0.0000e+00   0.0000e+00   0.0000e+00   3.6447e-03\n",
      "    0.0000e+00   0.0000e+00  -1.4189e-01  -3.7172e-01]\n",
      " [ -6.2954e-01  -1.7540e-01  -6.2954e-01  -6.8965e-01  -1.0995e+00\n",
      "   -6.8965e-01  -1.1744e+00   0.0000e+00  -3.8699e-01]\n",
      " [ -1.4320e-01  -1.5719e-01   0.0000e+00   0.0000e+00   0.0000e+00\n",
      "    0.0000e+00  -7.1078e-01   0.0000e+00   1.5603e+00]\n",
      " [ -3.7156e-01  -1.6202e-01  -6.2862e-01  -7.0039e-01  -1.1752e+00\n",
      "   -7.0039e-01  -1.1488e+00   0.0000e+00   1.5805e+01]\n",
      " [ -3.8744e-01   0.0000e+00   0.0000e+00   0.0000e+00  -2.3584e-01\n",
      "    0.0000e+00   0.0000e+00   1.5050e+01   4.1730e+01]\n",
      " [ -2.8495e-01   2.4774e+00   3.2256e+00   9.3509e-02  -4.4908e-01\n",
      "    1.0179e-01   2.8186e+00   8.0961e+00   0.0000e+00]\n",
      " [  1.7234e-01   1.8845e-01   1.7234e-01   1.8845e-01   0.0000e+00\n",
      "    1.8442e-01   2.4971e-01   3.0099e+00   0.0000e+00]]\n",
      "\n",
      "0 = up, 1 = right, 2 = down, 3 = left \n",
      "\n",
      "[[1 2 2 2 2 3 3 3 3]\n",
      " [1 1 1 3 3 3 1 1 3]\n",
      " [0 0 0 0 0 3 1 0 3]\n",
      " [1 1 3 3 0 3 3 0 2]\n",
      " [1 3 3 0 0 0 0 1 2]\n",
      " [0 0 3 3 3 1 3 2 2]\n",
      " [0 2 2 1 0 3 1 1 2]\n",
      " [1 2 2 2 1 2 2 1 0]\n",
      " [1 1 1 3 3 1 3 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rob/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:351: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "V, delta, count, policy = grid_world.non_deterministic_value_iteration()\n",
    "V.shape = (9,9)\n",
    "print('delta:', delta)\n",
    "print('number of iterations:', count)\n",
    "print('V: ', V)\n",
    "print(\"\\n0 = up, 1 = right, 2 = down, 3 = left \\n\")\n",
    "print(np.reshape(np.argmax(policy,axis=1),(9,9)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
