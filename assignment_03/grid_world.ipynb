{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GridWorld(object):\n",
    "    def __init__(self):\n",
    "        self.grid = np.array([[0,0,0,0,0,0,0,0,0],\n",
    "                              [0,1,1,1,1,2,0,0,0],\n",
    "                              [0,2,2,2,0,2,2,0,0],\n",
    "                              [0,0,0,0,0,0,0,2,0],\n",
    "                              [0,0,2,2,2,2,0,2,0],\n",
    "                              [0,0,0,0,0,0,0,2,0],\n",
    "                              [0,2,2,2,0,2,2,0,0],\n",
    "                              [0,0,0,0,0,0,0,0,3],\n",
    "                              [0,1,1,1,2,1,1,0,2]]) \n",
    "        self.rewards = {0:-1, 1:5, 2:-20, 3:100}\n",
    "        self.actions = np.array([[1, 0.125],[2, 0.125], [3, 0.625],[4, 0.125]]) # up, right, down, left\n",
    "        self.transition_probability = np.array([0.2,0.6,0.2]) # left diagonal, desired direction, right diagonal\n",
    "        self.gama = 0.9\n",
    "        self.threshold = 0.0001\n",
    "        self.n=9\n",
    "        self.a=4\n",
    "        self.states = self.n*self.n\n",
    "\n",
    "    def get_next_state(self,row,col,a):\n",
    "        # going up\n",
    "        if a == 1:\n",
    "            # if state is in row 0 it stays in same row\n",
    "            if row == 0:\n",
    "                r = row\n",
    "                c = col\n",
    "                reward = -10\n",
    "            else:\n",
    "                # if next state is not reachable\n",
    "                reward = self.rewards[self.grid[row-1,col]]\n",
    "                if self.grid[row-1,col] == 2:\n",
    "                    r = row\n",
    "                    c = col\n",
    "                # if next state is reachable and no obstacle\n",
    "                else:\n",
    "                    r = row-1\n",
    "                    c = col\n",
    "        # go right\n",
    "        elif a == 2:\n",
    "            # if state is in last column it stays in same column\n",
    "            if col == 8:\n",
    "                r = row\n",
    "                c = col\n",
    "                reward = -10\n",
    "            else:\n",
    "                # if next state is not reachable\n",
    "                reward = self.rewards[self.grid[row,col+1]]\n",
    "                if self.grid[row,col+1] == 2:\n",
    "                    r = row\n",
    "                    c = col\n",
    "                # if next state is reachable and no obstacle\n",
    "                else:\n",
    "                    r = row\n",
    "                    c = col+1\n",
    "        # go down\n",
    "        elif a == 3:\n",
    "            # if state is in row 8 it stays in same row\n",
    "            if row == 8:\n",
    "                r = row\n",
    "                c = col\n",
    "                reward = -10\n",
    "            else:\n",
    "                # if next state is not reachable\n",
    "                reward = self.rewards[self.grid[row+1,col]]\n",
    "                if self.grid[row+1,col] == 2:\n",
    "                    r = row\n",
    "                    c = col\n",
    "                # if next state is reachable and no obstacle\n",
    "                else:\n",
    "                    r = row+1\n",
    "                    c = col\n",
    "        # go left\n",
    "        elif a == 4:\n",
    "            # if state is in first column it stays in same column\n",
    "            if col == 0:\n",
    "                r = row\n",
    "                c = col\n",
    "                reward = -10\n",
    "            else:\n",
    "                # if next state is not reachable\n",
    "                reward = self.rewards[self.grid[row,col-1]]\n",
    "                if self.grid[row,col-1] == 2:\n",
    "                    r = row\n",
    "                    c = col\n",
    "                # if next state is reachable and no obstacle\n",
    "                else:\n",
    "                    r = row\n",
    "                    c = col-1\n",
    "        return r,c,reward\n",
    "    \n",
    "    def get_next_non_determinstic_state(self,row,col,a):\n",
    "        self.possible_states = np.zeros((3,4))\n",
    "        if a == 1:\n",
    "            for i in range(3):\n",
    "                # Diagonaly left\n",
    "                if i == 0:\n",
    "                    if row == 0:\n",
    "                        r = row\n",
    "                        c = col\n",
    "                        reward = -10\n",
    "                    else:\n",
    "                        if col == 0:\n",
    "                            r = row\n",
    "                            c = col\n",
    "                            reward = -10\n",
    "                        else:\n",
    "                            reward = self.rewards[self.grid[row-1,col-1]]\n",
    "                            if self.grid[row-1,col] == 2:\n",
    "                                r = row\n",
    "                                c = col\n",
    "                            # if next state is reachable and no obstacle\n",
    "                            else:\n",
    "                                r = row-1\n",
    "                                c = col-1\n",
    "                    prob = self.transition_probability[i]\n",
    "                # Desired direction\n",
    "                if i == 1:\n",
    "                    if row == 0:\n",
    "                        r = row\n",
    "                        c = col\n",
    "                        reward = -10\n",
    "                    else:\n",
    "                        reward = self.rewards[self.grid[row-1,col]]\n",
    "                        if self.grid[row-1,col] == 2:\n",
    "                            r = row\n",
    "                            c = col\n",
    "                        # if next state is reachable and no obstacle\n",
    "                        else:\n",
    "                            r = row-1\n",
    "                            c = col\n",
    "                    prob = self.transition_probability[i]\n",
    "                # Diagonally right\n",
    "                if i == 2:\n",
    "                    if row == 0:\n",
    "                        r = row\n",
    "                        c = col\n",
    "                        reward = -10\n",
    "                    else:\n",
    "                        if col == 8:\n",
    "                            r = row\n",
    "                            c = col\n",
    "                            reward = -10\n",
    "                        else:\n",
    "                            reward = self.rewards[self.grid[row-1,col+1]]\n",
    "                            if self.grid[row-1,col+1] == 2:\n",
    "                                r = row\n",
    "                                c = col\n",
    "                            # if next state is reachable and no obstacle\n",
    "                            else:\n",
    "                                r = row-1\n",
    "                                c = col+1\n",
    "                    prob = self.transition_probability[i]\n",
    "                self.possible_states[i,:] = np.array([r,c,reward,prob])\n",
    "        if a == 2:\n",
    "            for i in range(3):\n",
    "                # Diagonaly left\n",
    "                if i == 0:\n",
    "                    if col == 8:\n",
    "                        r = row\n",
    "                        c = col\n",
    "                        reward = -10\n",
    "                    else:\n",
    "                        if row == 0:\n",
    "                            r = row\n",
    "                            c = col\n",
    "                            reward = -10\n",
    "                        else:\n",
    "                            reward = self.rewards[self.grid[row-1,col+1]]\n",
    "                            if self.grid[row-1,col+1] == 2:\n",
    "                                r = row\n",
    "                                c = col\n",
    "                            # if next state is reachable and no obstacle\n",
    "                            else:\n",
    "                                r = row-1\n",
    "                                c = col+1\n",
    "                    prob = self.transition_probability[i]\n",
    "                # Desired direction\n",
    "                if i == 1:\n",
    "                    if col == 8:\n",
    "                        r = row\n",
    "                        c = col\n",
    "                        reward = -10\n",
    "                    else:\n",
    "                        reward = self.rewards[self.grid[row,col+1]]\n",
    "                        if self.grid[row,col+1] == 2:\n",
    "                            r = row\n",
    "                            c = col\n",
    "                        # if next state is reachable and no obstacle\n",
    "                        else:\n",
    "                            r = row\n",
    "                            c = col+1\n",
    "                    prob = self.transition_probability[i]\n",
    "                # Diagonally right\n",
    "                if i == 2:\n",
    "                    if col == 8:\n",
    "                        r = row\n",
    "                        c = col\n",
    "                        reward = -10\n",
    "                    else:\n",
    "                        if row == 8:\n",
    "                            r = row\n",
    "                            c = col\n",
    "                            reward = -10\n",
    "                        else:\n",
    "                            reward = self.rewards[self.grid[row+1,col+1]]\n",
    "                            if self.grid[row+1,col+1] == 2:\n",
    "                                r = row\n",
    "                                c = col\n",
    "                            # if next state is reachable and no obstacle\n",
    "                            else:\n",
    "                                r = row+1\n",
    "                                c = col+1\n",
    "                    prob = self.transition_probability[i]\n",
    "                self.possible_states[i,:] = np.array([r,c,reward,prob])\n",
    "        if a == 3:\n",
    "            for i in range(3):\n",
    "                # Diagonaly left\n",
    "                if i == 0:\n",
    "                    if row == 8:\n",
    "                        r = row\n",
    "                        c = col\n",
    "                        reward = -10\n",
    "                    else:\n",
    "                        if col == 8:\n",
    "                            r = row\n",
    "                            c = col\n",
    "                            reward = -10\n",
    "                        else:\n",
    "                            reward = self.rewards[self.grid[row+1,col+1]]\n",
    "                            if self.grid[row+1,col+1] == 2:\n",
    "                                r = row\n",
    "                                c = col\n",
    "                            # if next state is reachable and no obstacle\n",
    "                            else:\n",
    "                                r = row+1\n",
    "                                c = col+1\n",
    "                    prob = self.transition_probability[i]\n",
    "                # Desired direction\n",
    "                if i == 1:\n",
    "                    if row == 8:\n",
    "                        r = row\n",
    "                        c = col\n",
    "                        reward = -10\n",
    "                    else:\n",
    "                        reward = self.rewards[self.grid[row+1,col]]\n",
    "                        if self.grid[row+1,col] == 2:\n",
    "                            r = row\n",
    "                            c = col\n",
    "                        # if next state is reachable and no obstacle\n",
    "                        else:\n",
    "                            r = row+1\n",
    "                            c = col\n",
    "                    prob = self.transition_probability[i]\n",
    "                # Diagonally right\n",
    "                if i == 2:\n",
    "                    if row == 8:\n",
    "                        r = row\n",
    "                        c = col\n",
    "                        reward = -10\n",
    "                    else:\n",
    "                        if col == 0:\n",
    "                            r = row\n",
    "                            c = col\n",
    "                            reward = -10\n",
    "                        else:\n",
    "                            reward = self.rewards[self.grid[row+1,col-1]]\n",
    "                            if self.grid[row+1,col-1] == 2:\n",
    "                                r = row\n",
    "                                c = col\n",
    "                            # if next state is reachable and no obstacle\n",
    "                            else:\n",
    "                                r = row+1\n",
    "                                c = col-1\n",
    "                    prob = self.transition_probability[i]\n",
    "                self.possible_states[i,:] = np.array([r,c,reward,prob])\n",
    "        if a == 4:\n",
    "            for i in range(3):\n",
    "                # Diagonaly left\n",
    "                if i == 0:\n",
    "                    if col == 0:\n",
    "                        r = row\n",
    "                        c = col\n",
    "                        reward = -10\n",
    "                    else:\n",
    "                        if row == 8:\n",
    "                            r = row\n",
    "                            c = col\n",
    "                            reward = -10\n",
    "                        else:\n",
    "                            reward = self.rewards[self.grid[row+1,col-1]]\n",
    "                            if self.grid[row+1,col-1] == 2:\n",
    "                                r = row\n",
    "                                c = col\n",
    "                            # if next state is reachable and no obstacle\n",
    "                            else:\n",
    "                                r = row+1\n",
    "                                c = col-1\n",
    "                    prob = self.transition_probability[i]\n",
    "                # Desired direction\n",
    "                if i == 1:\n",
    "                    if col == 0:\n",
    "                        r = row\n",
    "                        c = col\n",
    "                        reward = -10\n",
    "                    else:\n",
    "                        reward = self.rewards[self.grid[row,col-1]]\n",
    "                        if self.grid[row,col-1] == 2:\n",
    "                            r = row\n",
    "                            c = col\n",
    "                        # if next state is reachable and no obstacle\n",
    "                        else:\n",
    "                            r = row\n",
    "                            c = col-1\n",
    "                    prob = self.transition_probability[i]\n",
    "                # Diagonally right\n",
    "                if i == 2:\n",
    "                    if col == 0:\n",
    "                        r = row\n",
    "                        c = col\n",
    "                        reward = -10\n",
    "                    else:\n",
    "                        if row == 0:\n",
    "                            r = row\n",
    "                            c = col\n",
    "                            reward = -10\n",
    "                        else:\n",
    "                            reward = self.rewards[self.grid[row-1,col-1]]\n",
    "                            if self.grid[row-1,col-1] == 2:\n",
    "                                r = row\n",
    "                                c = col\n",
    "                            # if next state is reachable and no obstacle\n",
    "                            else:\n",
    "                                r = row-1\n",
    "                                c = col-1\n",
    "                    prob = self.transition_probability[i]\n",
    "                self.possible_states[i,:] = np.array([r,c,reward,prob])\n",
    "        return self.possible_states\n",
    "        \n",
    "    # get the expected reward of state\n",
    "    def get_value(self,row,col):\n",
    "        index = row*9 + col\n",
    "        return self.V[index]\n",
    "    \n",
    "    # get the values \n",
    "    def get_next_state_value(self, row, col):\n",
    "        A_v = np.zeros(self.a)\n",
    "        for j in range(1,5): # for each action\n",
    "            r,c,reward = self.get_next_state(row,col,j) # get next state and reward\n",
    "            next_s = r*9 + c\n",
    "            next_v = self.get_value(r,c) # get value from nest state\n",
    "            prob = self.actions[j-1,1] # probability of action\n",
    "            A_v[j-1]  += prob*(reward + self.gama*next_v)\n",
    "        return A_v\n",
    "    \n",
    "    def get_next_non_deterministic_state_value(self, row, col):\n",
    "        A_v = np.zeros(self.a)\n",
    "        for j in range(1,5): # for each action\n",
    "            possible_states = self.get_next_non_determinstic_state(row,col,j) # get next state and reward\n",
    "            for s in range(3):\n",
    "                next_s = possible_states[s,0]*9 + possible_states[s,1]\n",
    "                next_v = self.get_value(possible_states[s,0],possible_states[s,1]) # get value from nest state\n",
    "                prob = self.actions[j-1,1] # probability of action\n",
    "                A_v[j-1]  +=  possible_states[s,3]*prob*(possible_states[s,2] + self.gama*next_v)\n",
    "        return A_v\n",
    "\n",
    "    def policy_evaluation(self):        \n",
    "        self.V = np.zeros(self.states)\n",
    "        count = 0\n",
    "        iterate = True\n",
    "        while iterate:\n",
    "        #     print(count)\n",
    "            delta = 0\n",
    "            for i in range(self.states):\n",
    "                row = int(i / self.n)\n",
    "                col = i % self.n\n",
    "                s = self.grid[row,col]\n",
    "                v = 0\n",
    "                if s != 2 and s != 3:\n",
    "                    for j in range(1,5): # for each action\n",
    "                        r,c,reward = self.get_next_state(row,col,j) # get next state and reward\n",
    "                        next_s = r*9 + c\n",
    "                        next_v = self.get_value(r,c) # get value from nest state\n",
    "                        prob = self.actions[j-1,1] # probability of action\n",
    "                        v  += prob*(reward + self.gama*next_v)\n",
    "        #                 print(\" row: \" + str(row) + \" col: \" + str(col))\n",
    "        #                 print(\"a: \" + str(j) + \" r: \" + str(r) + \" c: \" + str(c) + \" nest state: \" + str(next_s) + \" reward: \" + str(reward) + \" prob: \" + str(prob) + \" v: \" + str(prob*(reward + gama*next_v)))\n",
    "                    delta = max(delta, np.abs(v - self.V[i]))\n",
    "                self.V[i] = v\n",
    "            count += 1\n",
    "            if delta < self.threshold:\n",
    "                break\n",
    "        return self.V, delta, count\n",
    "\n",
    "    def value_iteration(self):        \n",
    "        self.V = np.zeros(self.states)\n",
    "        self.policy = np.zeros((self.states,self.a))\n",
    "        count = 0\n",
    "        iterate = True\n",
    "        while iterate:\n",
    "        #     print(count)\n",
    "            delta = 0\n",
    "            for i in range(self.states):\n",
    "                row = int(i / self.n)\n",
    "                col = i % self.n\n",
    "                s = self.grid[row,col]\n",
    "                best_v = 0\n",
    "                if s != 2 and s != 3:\n",
    "                    values = self.get_next_state_value(row,col)\n",
    "                    best_v = max(values)\n",
    "                    delta = max(delta, np.abs(best_v- self.V[i]))\n",
    "                self.V[i] = best_v\n",
    "            count += 1\n",
    "            if delta < self.threshold:\n",
    "                break\n",
    "        \n",
    "        for i in range(self.states):\n",
    "            row = int(i / self.n)\n",
    "            col = i % self.n\n",
    "            values = self.get_next_state_value(row,col)\n",
    "            best_v = np.argmax(values)\n",
    "            self.policy[i,best_v] = 1\n",
    "        # Deterministic policy     \n",
    "        return self.V, delta, count, self.policy\n",
    "\n",
    "    def non_deterministic_value_iteration(self):        \n",
    "        self.V = np.zeros(self.states)\n",
    "        self.policy = np.zeros((self.states,self.a))\n",
    "        count = 0\n",
    "        iterate = True\n",
    "        while iterate:\n",
    "        #     print(count)\n",
    "            delta = 0\n",
    "            for i in range(self.states):\n",
    "                row = int(i / self.n)\n",
    "                col = i % self.n\n",
    "                s = self.grid[row,col]\n",
    "                best_v = 0\n",
    "                if s != 2 and s != 3:\n",
    "                    values = self.get_next_non_deterministic_state_value(row,col)\n",
    "                    best_v = max(values)\n",
    "                    delta = max(delta, np.abs(best_v- self.V[i]))\n",
    "                self.V[i] = best_v\n",
    "            count += 1\n",
    "            if delta < self.threshold:\n",
    "                break\n",
    "        \n",
    "        for i in range(self.states):\n",
    "            row = int(i / self.n)\n",
    "            col = i % self.n\n",
    "            values = self.get_next_state_value(row,col)\n",
    "            best_v = np.argmax(values)\n",
    "            self.policy[i,best_v] = 1\n",
    "        # Deterministic policy     \n",
    "        return self.V, delta, count, self.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_world = GridWorld()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.84684316986e-05\n",
      "91\n",
      "[[ -50.1324936   -64.58247582  -72.65010404  -76.66298262  -80.8102371\n",
      "   -99.15175631  -81.18403045  -50.63043609  -20.12029228]\n",
      " [ -50.3772763   -80.22926875  -89.26562608  -93.15408361  -95.22664654\n",
      "     0.          -94.35615829  -55.8449427   -11.81743254]\n",
      " [ -50.96744537    0.            0.            0.         -110.7870577\n",
      "     0.            0.          -66.1413208     0.32553778]\n",
      " [ -52.14645007  -76.29940005 -118.74797657 -131.19534114 -124.70584532\n",
      "  -128.54082796 -111.07930378    0.           19.88315053]\n",
      " [ -53.04445287  -80.20470504    0.            0.            0.            0.\n",
      "  -117.11229547    0.           35.32945071]\n",
      " [ -53.44443734  -94.67650531 -120.093197   -116.70428329  -81.49735801\n",
      "  -119.75857851 -128.91671857    0.           52.69949744]\n",
      " [ -51.0015617     0.            0.            0.          -75.29221383\n",
      "     0.            0.          -14.75467424   73.54230193]\n",
      " [ -51.58001462  -46.34092771  -46.60471602  -55.31555955  -77.21430575\n",
      "   -55.22588857  -44.45109547  -24.81493291    0.        ]\n",
      " [ -58.13560721  -54.14548168  -53.86732506  -63.17858985    0.\n",
      "   -63.46781606  -54.7924953   -52.94097625    0.        ]]\n"
     ]
    }
   ],
   "source": [
    "V,delta, count = grid_world.policy_evaluation()\n",
    "V.shape = (9,9)\n",
    "print(delta)\n",
    "print(count)\n",
    "print(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6074364062e-12\n",
      "9\n",
      "[[  2.71126761e-01   3.52112676e+00   3.52112676e+00   3.52112676e+00\n",
      "    3.52112676e+00   2.71126761e-01  -9.44982394e-02  -5.78990933e-02\n",
      "    5.96452504e-01]\n",
      " [  7.04225352e-01   7.04225352e-01   7.04225352e-01   7.04225352e-01\n",
      "    7.04225352e-01   0.00000000e+00  -1.11579819e-01   1.19290501e-01\n",
      "    2.17147112e+00]\n",
      " [ -4.57746479e-02   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    7.04225352e-01   0.00000000e+00   0.00000000e+00   4.34294224e-01\n",
      "    4.97150421e+00]\n",
      " [ -1.30149648e-01  -1.39641835e-01  -1.39641835e-01  -1.30149648e-01\n",
      "   -4.57746479e-02  -1.30149648e-01  -1.39641835e-01   0.00000000e+00\n",
      "    9.94934082e+00]\n",
      " [ -1.39641835e-01  -1.40709706e-01   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00  -1.40709706e-01   0.00000000e+00\n",
      "    1.87988281e+01]\n",
      " [ -1.40709706e-01  -1.40829842e-01  -1.40843357e-01  -1.40844878e-01\n",
      "   -1.40844878e-01  -1.40843357e-01  -1.40829842e-01   0.00000000e+00\n",
      "    3.45312500e+01]\n",
      " [ -1.40829842e-01   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   -1.40845049e-01   0.00000000e+00   0.00000000e+00   6.90625000e+00\n",
      "    6.25000000e+01]\n",
      " [  2.71126761e-01   3.52112676e+00   3.52112676e+00   3.52112676e+00\n",
      "    2.71126761e-01   3.52112676e+00   3.52112676e+00   1.25000000e+01\n",
      "    0.00000000e+00]\n",
      " [  7.04225352e-01   7.04225352e-01   7.04225352e-01   7.04225352e-01\n",
      "    0.00000000e+00   7.04225352e-01   7.04225352e-01   1.28125000e+00\n",
      "    0.00000000e+00]]\n",
      "\n",
      "0 = up, 1 = right, 2 = down, 3 = left \n",
      "\n",
      "[[1 2 2 2 2 3 3 1 2]\n",
      " [1 1 1 1 3 3 1 1 2]\n",
      " [0 0 0 0 0 3 1 1 2]\n",
      " [0 3 1 1 0 3 3 1 2]\n",
      " [0 0 0 0 0 0 0 1 2]\n",
      " [0 0 3 3 1 1 0 1 2]\n",
      " [0 2 2 2 0 2 2 1 2]\n",
      " [1 2 2 2 3 2 2 1 0]\n",
      " [1 1 1 3 1 1 3 0 0]]\n"
     ]
    }
   ],
   "source": [
    "V, delta, count, policy = grid_world.value_iteration()\n",
    "V.shape = (9,9)\n",
    "print(delta)\n",
    "print(count)\n",
    "print(V)\n",
    "print(\"\\n0 = up, 1 = right, 2 = down, 3 = left \\n\")\n",
    "print(np.reshape(np.argmax(policy,axis=1),(9,9)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.41781135388e-05\n",
      "12\n",
      "[[ -3.44243869e-02   2.42739026e+00   3.24868693e+00   3.25252722e+00\n",
      "    2.74076201e-02  -2.03966779e-01  -3.88366809e-01  -3.88262459e-01\n",
      "   -3.88366809e-01]\n",
      " [ -8.99025689e-02   1.11169750e-01   2.22084511e-01   3.22016055e-01\n",
      "   -5.45573757e-02   0.00000000e+00  -1.47190863e-01  -1.52037335e-01\n",
      "   -1.47190863e-01]\n",
      " [ -2.08252792e-01   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    3.64474515e-03   0.00000000e+00   0.00000000e+00  -1.41886109e-01\n",
      "   -3.71719922e-01]\n",
      " [ -6.29541091e-01  -1.75401765e-01  -6.29541091e-01  -6.89650886e-01\n",
      "   -1.09949256e+00  -6.89650886e-01  -1.17439941e+00   0.00000000e+00\n",
      "   -3.86990826e-01]\n",
      " [ -1.43202384e-01  -1.57191006e-01   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00  -7.10781693e-01   0.00000000e+00\n",
      "    1.56032098e+00]\n",
      " [ -3.71563129e-01  -1.62020042e-01  -6.28617034e-01  -7.00388340e-01\n",
      "   -1.17515834e+00  -7.00388340e-01  -1.14882636e+00   0.00000000e+00\n",
      "    1.58051977e+01]\n",
      " [ -3.87443440e-01   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   -2.35840663e-01   0.00000000e+00   0.00000000e+00   1.50495301e+01\n",
      "    4.17304913e+01]\n",
      " [ -2.84948271e-01   2.47737750e+00   3.22556521e+00   9.35091627e-02\n",
      "   -4.49084246e-01   1.01786676e-01   2.81863949e+00   8.09609827e+00\n",
      "    0.00000000e+00]\n",
      " [  1.72338870e-01   1.88448175e-01   1.72338870e-01   1.88448175e-01\n",
      "    0.00000000e+00   1.84424402e-01   2.49710577e-01   3.00990602e+00\n",
      "    0.00000000e+00]]\n",
      "\n",
      "0 = up, 1 = right, 2 = down, 3 = left \n",
      "\n",
      "[[1 2 2 2 2 3 3 3 3]\n",
      " [1 1 1 3 3 3 1 1 3]\n",
      " [0 0 0 0 0 3 1 0 3]\n",
      " [1 1 3 3 0 3 3 0 2]\n",
      " [1 3 3 0 0 0 0 1 2]\n",
      " [0 0 3 3 3 1 3 2 2]\n",
      " [0 2 2 1 0 3 1 1 2]\n",
      " [1 2 2 2 1 2 2 1 0]\n",
      " [1 1 1 3 3 1 3 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rob/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:343: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "V, delta, count, policy = grid_world.non_deterministic_value_iteration()\n",
    "V.shape = (9,9)\n",
    "print(delta)\n",
    "print(count)\n",
    "print(V)\n",
    "print(\"\\n0 = up, 1 = right, 2 = down, 3 = left \\n\")\n",
    "print(np.reshape(np.argmax(policy,axis=1),(9,9)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
