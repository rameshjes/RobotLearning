{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GridWorld(object):\n",
    "    def __init__(self):\n",
    "        self.grid = np.array([[0,0,0,0,0,0,0,0,0],\n",
    "                              [0,1,1,1,1,2,0,0,0],\n",
    "                              [0,2,2,2,0,2,2,0,0],\n",
    "                              [0,0,0,0,0,0,0,2,0],\n",
    "                              [0,0,2,2,2,2,0,2,0],\n",
    "                              [0,0,0,0,0,0,0,2,0],\n",
    "                              [0,2,2,2,0,2,2,0,0],\n",
    "                              [0,0,0,0,0,0,0,0,3],\n",
    "                              [0,1,1,1,2,1,1,0,2]]) \n",
    "        self.rewards = {0:-1, 1:5, 2:-20, 3:100}\n",
    "        self.actions = np.array([[1, 0.125],[2, 0.125], [3, 0.625],[4, 0.125]]) # up, right, down, left\n",
    "        self.transition_probability = np.array([0.2,0.6,0.2]) # left diagonal, desired direction, right diagonal\n",
    "        self.gama = 0.9\n",
    "        self.threshold = 0.01\n",
    "        self.n=9\n",
    "        self.a=4\n",
    "        self.states = n*n\n",
    "\n",
    "    def get_next_state(self,row,col,a):\n",
    "        # going up\n",
    "        if a == 1:\n",
    "            # if state is in row 0 it stays in same row\n",
    "            if row == 0:\n",
    "                r = row\n",
    "                c = col\n",
    "                reward = -10\n",
    "            else:\n",
    "                # if next state is not reachable\n",
    "                reward = self.rewards[grid[row-1,col]]\n",
    "                if grid[row-1,col] == 2:\n",
    "                    r = row\n",
    "                    c = col\n",
    "                # if next state is reachable and no obstacle\n",
    "                else:\n",
    "                    r = row-1\n",
    "                    c = col\n",
    "        # go right\n",
    "        elif a == 2:\n",
    "            # if state is in last column it stays in same column\n",
    "            if col == 8:\n",
    "                r = row\n",
    "                c = col\n",
    "                reward = -10\n",
    "            else:\n",
    "                # if next state is not reachable\n",
    "                reward = self.rewards[grid[row,col+1]]\n",
    "                if grid[row,col+1] == 2:\n",
    "                    r = row\n",
    "                    c = col\n",
    "                # if next state is reachable and no obstacle\n",
    "                else:\n",
    "                    r = row\n",
    "                    c = col+1\n",
    "        # go down\n",
    "        elif a == 3:\n",
    "            # if state is in row 8 it stays in same row\n",
    "            if row == 8:\n",
    "                r = row\n",
    "                c = col\n",
    "                reward = -10\n",
    "            else:\n",
    "                # if next state is not reachable\n",
    "                reward = self.rewards[grid[row+1,col]]\n",
    "                if grid[row+1,col] == 2:\n",
    "                    r = row\n",
    "                    c = col\n",
    "                # if next state is reachable and no obstacle\n",
    "                else:\n",
    "                    r = row+1\n",
    "                    c = col\n",
    "        # go left\n",
    "        elif a == 4:\n",
    "            # if state is in first column it stays in same column\n",
    "            if col == 0:\n",
    "                r = row\n",
    "                c = col\n",
    "                reward = -10\n",
    "            else:\n",
    "                # if next state is not reachable\n",
    "                reward = self.rewards[grid[row,col-1]]\n",
    "                if grid[row,col-1] == 2:\n",
    "                    r = row\n",
    "                    c = col\n",
    "                # if next state is reachable and no obstacle\n",
    "                else:\n",
    "                    r = row\n",
    "                    c = col-1\n",
    "        return r,c,reward\n",
    "    \n",
    "    def get_next_non_determinstic_state(self,row,col,a):\n",
    "        self.possible_states = np.zeros((3,4))\n",
    "        if a == 1:\n",
    "            for i in range(3):\n",
    "                # Diagonaly left\n",
    "                if i == 0:\n",
    "                    if row == 0:\n",
    "                        r = row\n",
    "                        c = col\n",
    "                        reward = -10\n",
    "                    else:\n",
    "                        if col == 0:\n",
    "                            r = row\n",
    "                            c = col\n",
    "                            reward = -10\n",
    "                        else:\n",
    "                            reward = self.rewards[grid[row-1,col-1]]\n",
    "                            if grid[row-1,col] == 2:\n",
    "                                r = row\n",
    "                                c = col\n",
    "                            # if next state is reachable and no obstacle\n",
    "                            else:\n",
    "                                r = row-1\n",
    "                                c = col-1\n",
    "                    prob = self.transition_probability[i]\n",
    "                # Desired direction\n",
    "                if i == 1:\n",
    "                    if row == 0:\n",
    "                        r = row\n",
    "                        c = col\n",
    "                        reward = -10\n",
    "                    else:\n",
    "                        reward = self.rewards[grid[row-1,col]]\n",
    "                        if grid[row-1,col] == 2:\n",
    "                            r = row\n",
    "                            c = col\n",
    "                        # if next state is reachable and no obstacle\n",
    "                        else:\n",
    "                            r = row-1\n",
    "                            c = col\n",
    "                    prob = self.transition_probability[i]\n",
    "                # Diagonally right\n",
    "                if i == 2:\n",
    "                    if row == 0:\n",
    "                        r = row\n",
    "                        c = col\n",
    "                        reward = -10\n",
    "                    else:\n",
    "                        if col == 8:\n",
    "                            r = row\n",
    "                            c = col\n",
    "                            reward = -10\n",
    "                        else:\n",
    "                            reward = self.rewards[grid[row-1,col+1]]\n",
    "                            if grid[row-1,col+1] == 2:\n",
    "                                r = row\n",
    "                                c = col\n",
    "                            # if next state is reachable and no obstacle\n",
    "                            else:\n",
    "                                r = row-1\n",
    "                                c = col+1\n",
    "                    prob = self.transition_probability[i]\n",
    "                self.possible_states[i,:] = np.array([r,c,reward,prob])\n",
    "        if a == 2:\n",
    "            for i in range(3):\n",
    "                # Diagonaly left\n",
    "                if i == 0:\n",
    "                    if col == 8:\n",
    "                        r = row\n",
    "                        c = col\n",
    "                        reward = -10\n",
    "                    else:\n",
    "                        if row == 0:\n",
    "                            r = row\n",
    "                            c = col\n",
    "                            reward = -10\n",
    "                        else:\n",
    "                            reward = self.rewards[grid[row-1,col+1]]\n",
    "                            if grid[row-1,col+1] == 2:\n",
    "                                r = row\n",
    "                                c = col\n",
    "                            # if next state is reachable and no obstacle\n",
    "                            else:\n",
    "                                r = row-1\n",
    "                                c = col+1\n",
    "                    prob = self.transition_probability[i]\n",
    "                # Desired direction\n",
    "                if i == 1:\n",
    "                    if col == 8:\n",
    "                        r = row\n",
    "                        c = col\n",
    "                        reward = -10\n",
    "                    else:\n",
    "                        reward = self.rewards[grid[row,col+1]]\n",
    "                        if grid[row,col+1] == 2:\n",
    "                            r = row\n",
    "                            c = col\n",
    "                        # if next state is reachable and no obstacle\n",
    "                        else:\n",
    "                            r = row\n",
    "                            c = col+1\n",
    "                    prob = self.transition_probability[i]\n",
    "                # Diagonally right\n",
    "                if i == 2:\n",
    "                    if col == 8:\n",
    "                        r = row\n",
    "                        c = col\n",
    "                        reward = -10\n",
    "                    else:\n",
    "                        if row == 8:\n",
    "                            r = row\n",
    "                            c = col\n",
    "                            reward = -10\n",
    "                        else:\n",
    "                            reward = self.rewards[grid[row+1,col+1]]\n",
    "                            if grid[row+1,col+1] == 2:\n",
    "                                r = row\n",
    "                                c = col\n",
    "                            # if next state is reachable and no obstacle\n",
    "                            else:\n",
    "                                r = row+1\n",
    "                                c = col+1\n",
    "                    prob = self.transition_probability[i]\n",
    "                self.possible_states[i,:] = np.array([r,c,reward,prob])\n",
    "        if a == 3:\n",
    "            for i in range(3):\n",
    "                # Diagonaly left\n",
    "                if i == 0:\n",
    "                    if row == 8:\n",
    "                        r = row\n",
    "                        c = col\n",
    "                        reward = -10\n",
    "                    else:\n",
    "                        if col == 8:\n",
    "                            r = row\n",
    "                            c = col\n",
    "                            reward = -10\n",
    "                        else:\n",
    "                            reward = self.rewards[grid[row+1,col+1]]\n",
    "                            if grid[row+1,col+1] == 2:\n",
    "                                r = row\n",
    "                                c = col\n",
    "                            # if next state is reachable and no obstacle\n",
    "                            else:\n",
    "                                r = row+1\n",
    "                                c = col+1\n",
    "                    prob = self.transition_probability[i]\n",
    "                # Desired direction\n",
    "                if i == 1:\n",
    "                    if row == 8:\n",
    "                        r = row\n",
    "                        c = col\n",
    "                        reward = -10\n",
    "                    else:\n",
    "                        reward = self.rewards[grid[row+1,col]]\n",
    "                        if grid[row+1,col] == 2:\n",
    "                            r = row\n",
    "                            c = col\n",
    "                        # if next state is reachable and no obstacle\n",
    "                        else:\n",
    "                            r = row+1\n",
    "                            c = col\n",
    "                    prob = self.transition_probability[i]\n",
    "                # Diagonally right\n",
    "                if i == 2:\n",
    "                    if row == 8:\n",
    "                        r = row\n",
    "                        c = col\n",
    "                        reward = -10\n",
    "                    else:\n",
    "                        if col == 0:\n",
    "                            r = row\n",
    "                            c = col\n",
    "                            reward = -10\n",
    "                        else:\n",
    "                            reward = self.rewards[grid[row+1,col-1]]\n",
    "                            if grid[row+1,col-1] == 2:\n",
    "                                r = row\n",
    "                                c = col\n",
    "                            # if next state is reachable and no obstacle\n",
    "                            else:\n",
    "                                r = row+1\n",
    "                                c = col-1\n",
    "                    prob = self.transition_probability[i]\n",
    "                self.possible_states[i,:] = np.array([r,c,reward,prob])\n",
    "        if a == 4:\n",
    "            for i in range(3):\n",
    "                # Diagonaly left\n",
    "                if i == 0:\n",
    "                    if col == 0:\n",
    "                        r = row\n",
    "                        c = col\n",
    "                        reward = -10\n",
    "                    else:\n",
    "                        if row == 8:\n",
    "                            r = row\n",
    "                            c = col\n",
    "                            reward = -10\n",
    "                        else:\n",
    "                            reward = self.rewards[grid[row+1,col-1]]\n",
    "                            if grid[row+1,col-1] == 2:\n",
    "                                r = row\n",
    "                                c = col\n",
    "                            # if next state is reachable and no obstacle\n",
    "                            else:\n",
    "                                r = row+1\n",
    "                                c = col-1\n",
    "                    prob = self.transition_probability[i]\n",
    "                # Desired direction\n",
    "                if i == 1:\n",
    "                    if col == 0:\n",
    "                        r = row\n",
    "                        c = col\n",
    "                        reward = -10\n",
    "                    else:\n",
    "                        reward = self.rewards[grid[row,col-1]]\n",
    "                        if grid[row,col-1] == 2:\n",
    "                            r = row\n",
    "                            c = col\n",
    "                        # if next state is reachable and no obstacle\n",
    "                        else:\n",
    "                            r = row\n",
    "                            c = col-1\n",
    "                    prob = self.transition_probability[i]\n",
    "                # Diagonally right\n",
    "                if i == 2:\n",
    "                    if col == 0:\n",
    "                        r = row\n",
    "                        c = col\n",
    "                        reward = -10\n",
    "                    else:\n",
    "                        if row == 0:\n",
    "                            r = row\n",
    "                            c = col\n",
    "                            reward = -10\n",
    "                        else:\n",
    "                            reward = self.rewards[grid[row-1,col-1]]\n",
    "                            if grid[row-1,col-1] == 2:\n",
    "                                r = row\n",
    "                                c = col\n",
    "                            # if next state is reachable and no obstacle\n",
    "                            else:\n",
    "                                r = row-1\n",
    "                                c = col-1\n",
    "                    prob = self.transition_probability[i]\n",
    "                self.possible_states[i,:] = np.array([r,c,reward,prob])\n",
    "        return self.possible_states\n",
    "        \n",
    "    def get_value(self,row,col):\n",
    "        index = row*9 + col\n",
    "        return self.V[index]\n",
    "    \n",
    "    def get_next_state_value(self, row, col):\n",
    "        A_v = np.zeros(self.a)\n",
    "        for j in range(1,5): # for each action\n",
    "            r,c,reward = self.get_next_state(row,col,j) # get next state and reward\n",
    "            next_s = r*9 + c\n",
    "            next_v = self.get_value(r,c) # get value from nest state\n",
    "            prob = self.actions[j-1,1] # probability of action\n",
    "            A_v[j-1]  += prob*(reward + gama*next_v)\n",
    "        return A_v\n",
    "    \n",
    "    def get_next_non_deterministic_state_value(self, row, col):\n",
    "        A_v = np.zeros(self.a)\n",
    "        for j in range(1,5): # for each action\n",
    "            possible_states = self.get_next_non_determinstic_state(row,col,j) # get next state and reward\n",
    "            for s in range(3):\n",
    "                next_s = possible_states[s,0]*9 + possible_states[s,1]\n",
    "                next_v = self.get_value(possible_states[s,0],possible_states[s,1]) # get value from nest state\n",
    "                prob = self.actions[j-1,1] # probability of action\n",
    "                A_v[j-1]  +=  possible_states[s,3]*prob*(possible_states[s,2] + gama*next_v)\n",
    "        return A_v\n",
    "\n",
    "    def policy_evaluation(self):        \n",
    "        self.V = np.zeros(self.states)\n",
    "        count = 0\n",
    "        iterate = True\n",
    "        while iterate:\n",
    "        #     print(count)\n",
    "            delta = 0\n",
    "            for i in range(self.states):\n",
    "                row = int(i / n)\n",
    "                col = i % n\n",
    "                s = grid[row,col]\n",
    "                v = 0\n",
    "                if s != 2 and s != 3:\n",
    "                    for j in range(1,5): # for each action\n",
    "                        r,c,reward = self.get_next_state(row,col,j) # get next state and reward\n",
    "                        next_s = r*9 + c\n",
    "                        next_v = self.get_value(r,c) # get value from nest state\n",
    "                        prob = self.actions[j-1,1] # probability of action\n",
    "                        v  += prob*(reward + gama*next_v)\n",
    "        #                 print(\" row: \" + str(row) + \" col: \" + str(col))\n",
    "        #                 print(\"a: \" + str(j) + \" r: \" + str(r) + \" c: \" + str(c) + \" nest state: \" + str(next_s) + \" reward: \" + str(reward) + \" prob: \" + str(prob) + \" v: \" + str(prob*(reward + gama*next_v)))\n",
    "                    delta = max(delta, np.abs(v - self.V[i]))\n",
    "                self.V[i] = v\n",
    "            count += 1\n",
    "            if delta < self.threshold:\n",
    "                break\n",
    "        return self.V, delta, count\n",
    "\n",
    "    def value_iteration(self):        \n",
    "        self.V = np.zeros(self.states)\n",
    "        self.policy = np.zeros((self.states,self.a))\n",
    "        count = 0\n",
    "        iterate = True\n",
    "        while iterate:\n",
    "        #     print(count)\n",
    "            delta = 0\n",
    "            for i in range(self.states):\n",
    "                row = int(i / n)\n",
    "                col = i % n\n",
    "                s = grid[row,col]\n",
    "                best_v = 0\n",
    "                if s != 2 and s != 3:\n",
    "                    values = self.get_next_state_value(row,col)\n",
    "                    best_v = max(values)\n",
    "                    delta = max(delta, np.abs(best_v- self.V[i]))\n",
    "                self.V[i] = best_v\n",
    "            count += 1\n",
    "            if delta < self.threshold:\n",
    "                break\n",
    "        \n",
    "        for i in range(self.states):\n",
    "            row = int(i / n)\n",
    "            col = i % n\n",
    "            values = self.get_next_state_value(row,col)\n",
    "            best_v = np.argmax(values)\n",
    "            self.policy[i,best_v] = 1\n",
    "        # Deterministic policy     \n",
    "        return self.V, delta, count, self.policy\n",
    "\n",
    "    def non_deterministic_value_iteration(self):        \n",
    "        self.V = np.zeros(self.states)\n",
    "        self.policy = np.zeros((self.states,self.a))\n",
    "        count = 0\n",
    "        iterate = True\n",
    "        while iterate:\n",
    "        #     print(count)\n",
    "            delta = 0\n",
    "            for i in range(self.states):\n",
    "                row = int(i / n)\n",
    "                col = i % n\n",
    "                s = grid[row,col]\n",
    "                best_v = 0\n",
    "                if s != 2 and s != 3:\n",
    "                    values = self.get_next_non_deterministic_state_value(row,col)\n",
    "                    best_v = max(values)\n",
    "                    delta = max(delta, np.abs(best_v- self.V[i]))\n",
    "                self.V[i] = best_v\n",
    "            count += 1\n",
    "            if delta < self.threshold:\n",
    "                break\n",
    "        \n",
    "        for i in range(self.states):\n",
    "            row = int(i / n)\n",
    "            col = i % n\n",
    "            values = self.get_next_state_value(row,col)\n",
    "            best_v = np.argmax(values)\n",
    "            self.policy[i,best_v] = 1\n",
    "        # Deterministic policy     \n",
    "        return self.V, delta, count, self.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_world = GridWorld()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00898890227799\n",
      "57\n",
      "[[ -50.08612369  -64.53334339  -72.59725479  -76.60701104  -80.75454646\n",
      "   -99.117781    -81.17306149  -50.62544565  -20.11697798]\n",
      " [ -50.33345118  -80.18134925  -89.2138516   -93.09876195  -95.1679835\n",
      "     0.          -94.34828439  -55.84078722  -11.81449416]\n",
      " [ -50.92566932    0.            0.            0.         -110.72720052\n",
      "     0.            0.          -66.13771494    0.32820054]\n",
      " [ -52.10576651  -76.25650885 -118.69214086 -131.13425753 -124.64722049\n",
      "  -128.48502285 -111.03299206    0.           19.88560342]\n",
      " [ -53.00511534  -80.16484961    0.            0.            0.            0.\n",
      "  -117.06883055    0.           35.33180675]\n",
      " [ -53.40611199  -94.63685456 -120.05144636 -116.66504507  -81.46454262\n",
      "  -119.71828251 -128.87486324    0.           52.70177889]\n",
      " [ -50.96431816    0.            0.            0.          -75.26272895\n",
      "     0.            0.          -14.73982542   73.5445146 ]\n",
      " [ -51.5435615   -46.30713212  -46.57285074  -55.2849902   -77.18601655\n",
      "   -55.20006671  -44.4288945   -24.79829968    0.        ]\n",
      " [ -58.09934957  -54.11232087  -53.83607685  -63.14833284    0.\n",
      "   -63.44231997  -54.77035086  -52.92165561    0.        ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "V,delta, count = grid_world.policy_evaluation()\n",
    "V.shape = (9,9)\n",
    "print(delta)\n",
    "print(count)\n",
    "print(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6074364062e-12\n",
      "9\n",
      "[[  2.71126761e-01   3.52112676e+00   3.52112676e+00   3.52112676e+00\n",
      "    3.52112676e+00   2.71126761e-01  -9.44982394e-02  -5.78990933e-02\n",
      "    5.96452504e-01]\n",
      " [  7.04225352e-01   7.04225352e-01   7.04225352e-01   7.04225352e-01\n",
      "    7.04225352e-01   0.00000000e+00  -1.11579819e-01   1.19290501e-01\n",
      "    2.17147112e+00]\n",
      " [ -4.57746479e-02   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    7.04225352e-01   0.00000000e+00   0.00000000e+00   4.34294224e-01\n",
      "    4.97150421e+00]\n",
      " [ -1.30149648e-01  -1.39641835e-01  -1.39641835e-01  -1.30149648e-01\n",
      "   -4.57746479e-02  -1.30149648e-01  -1.39641835e-01   0.00000000e+00\n",
      "    9.94934082e+00]\n",
      " [ -1.39641835e-01  -1.40709706e-01   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00  -1.40709706e-01   0.00000000e+00\n",
      "    1.87988281e+01]\n",
      " [ -1.40709706e-01  -1.40829842e-01  -1.40843357e-01  -1.40844878e-01\n",
      "   -1.40844878e-01  -1.40843357e-01  -1.40829842e-01   0.00000000e+00\n",
      "    3.45312500e+01]\n",
      " [ -1.40829842e-01   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   -1.40845049e-01   0.00000000e+00   0.00000000e+00   6.90625000e+00\n",
      "    6.25000000e+01]\n",
      " [  2.71126761e-01   3.52112676e+00   3.52112676e+00   3.52112676e+00\n",
      "    2.71126761e-01   3.52112676e+00   3.52112676e+00   1.25000000e+01\n",
      "    0.00000000e+00]\n",
      " [  7.04225352e-01   7.04225352e-01   7.04225352e-01   7.04225352e-01\n",
      "    0.00000000e+00   7.04225352e-01   7.04225352e-01   1.28125000e+00\n",
      "    0.00000000e+00]]\n",
      "\n",
      "0 = up, 1 = right, 2 = down, 3 = left \n",
      "\n",
      "[[1 2 2 2 2 3 3 1 2]\n",
      " [1 1 1 1 3 3 1 1 2]\n",
      " [0 0 0 0 0 3 1 1 2]\n",
      " [0 3 1 1 0 3 3 1 2]\n",
      " [0 0 0 0 0 0 0 1 2]\n",
      " [0 0 3 3 1 1 0 1 2]\n",
      " [0 2 2 2 0 2 2 1 2]\n",
      " [1 2 2 2 3 2 2 1 0]\n",
      " [1 1 1 3 1 1 3 0 0]]\n"
     ]
    }
   ],
   "source": [
    "V, delta, count, policy = grid_world.value_iteration()\n",
    "V.shape = (9,9)\n",
    "print(delta)\n",
    "print(count)\n",
    "print(V)\n",
    "print(\"\\n0 = up, 1 = right, 2 = down, 3 = left \\n\")\n",
    "print(np.reshape(np.argmax(policy,axis=1),(9,9)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00868604831232\n",
      "8\n",
      "[[ -3.44243877e-02   2.42739026e+00   3.24868693e+00   3.25252722e+00\n",
      "    2.74076201e-02  -2.03966779e-01  -3.88366809e-01  -3.88262459e-01\n",
      "   -3.88366809e-01]\n",
      " [ -8.99025690e-02   1.11169750e-01   2.22084511e-01   3.22016055e-01\n",
      "   -5.45573757e-02   0.00000000e+00  -1.47190863e-01  -1.52037335e-01\n",
      "   -1.47190863e-01]\n",
      " [ -2.08252792e-01   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    3.64474515e-03   0.00000000e+00   0.00000000e+00  -1.41886109e-01\n",
      "   -3.71719922e-01]\n",
      " [ -6.29541091e-01  -1.75401765e-01  -6.29541091e-01  -6.89650886e-01\n",
      "   -1.09949256e+00  -6.89650886e-01  -1.17439941e+00   0.00000000e+00\n",
      "   -3.86990826e-01]\n",
      " [ -1.43202384e-01  -1.57191006e-01   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00  -7.10781693e-01   0.00000000e+00\n",
      "    1.55768724e+00]\n",
      " [ -3.71563129e-01  -1.62020042e-01  -6.28617034e-01  -7.00388340e-01\n",
      "   -1.17515834e+00  -7.00388340e-01  -1.14882636e+00   0.00000000e+00\n",
      "    1.58051621e+01]\n",
      " [ -3.87443440e-01   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   -2.35840663e-01   0.00000000e+00   0.00000000e+00   1.50495300e+01\n",
      "    4.17304897e+01]\n",
      " [ -2.84948272e-01   2.47737750e+00   3.22556521e+00   9.35091295e-02\n",
      "   -4.49084360e-01   1.01786502e-01   2.81863947e+00   8.09609822e+00\n",
      "    0.00000000e+00]\n",
      " [  1.72338870e-01   1.88448175e-01   1.72338870e-01   1.88448175e-01\n",
      "    0.00000000e+00   1.84424396e-01   2.49710570e-01   3.00990602e+00\n",
      "    0.00000000e+00]]\n",
      "\n",
      "0 = up, 1 = right, 2 = down, 3 = left \n",
      "\n",
      "[[1 2 2 2 2 3 3 3 3]\n",
      " [1 1 1 3 3 3 1 3 3]\n",
      " [0 0 0 0 0 3 1 0 3]\n",
      " [1 3 3 3 0 3 3 0 2]\n",
      " [1 3 3 0 0 0 0 1 2]\n",
      " [0 0 3 3 3 1 3 2 2]\n",
      " [0 2 2 1 0 3 1 1 2]\n",
      " [1 2 2 2 1 2 2 1 0]\n",
      " [1 1 1 3 3 1 3 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rob/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:342: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "V, delta, count, policy = grid_world.non_deterministic_value_iteration()\n",
    "V.shape = (9,9)\n",
    "print(delta)\n",
    "print(count)\n",
    "print(V)\n",
    "print(\"\\n0 = up, 1 = right, 2 = down, 3 = left \\n\")\n",
    "print(np.reshape(np.argmax(policy,axis=1),(9,9)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
